configfile:'configfile.yaml'

import numpy as np
import quantities as pq
from utils import estimate_number_spikes

# Loading parameters
winlen =config['winlen']
binsize = config['binsize']
rates = config['rate']
t_stops = config['t_stop']
ns = config['n']
keys = config['keys']

expected_num_spikes_dict = estimate_number_spikes(keys=keys,
                                                  ns=ns,
                                                  rates=rates,
                                                  t_stops=t_stops)

# Rule collecting all the outputs    
rule all:
    input:
        ['../results/{keys}/{expected_num_spikes}/profiling_results.npy'.format(keys=key, expected_num_spikes=expected_num_spikes)
         for key in keys for expected_num_spikes in expected_num_spikes_dict[key]]

# Rule to generate the artificial data
rule profile_data:
    input:
        'configfile.yaml'
    output:
        '../results/{keys}/{expected_num_spikes}/profiling_results.npy'
#    conda:
#        "/envs/SPADE_applications.yaml"
    shell:
        "python profiling.py {wildcards.keys} {wildcards.expected_num_spikes}"
